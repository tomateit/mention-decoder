{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0974e7a8-d0e8-4d54-80be-86d7776907ff",
   "metadata": {},
   "source": [
    "# Dataset from NER dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5082b82-b321-4ee4-8c9a-cbe65e1a1817",
   "metadata": {},
   "source": [
    "For our task we need to collect a dataset with following properties:\n",
    "1. Sentence contains just one named entity\n",
    "    + of type ORG for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c159597-3aae-485c-8b9a-eadde9833eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import pymongo\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "from preprocess import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7424dfd4-5e99-4a00-a70c-2b0480a55955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538362"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = pymongo.MongoClient()\n",
    "database = client[\"texts\"]\n",
    "collection = database[\"news\"]\n",
    "projection = {\"raw_text\": 1}\n",
    "texts = collection.find({}, projection)\n",
    "total_texts = collection.estimated_document_count()\n",
    "total_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930b9fa1-21da-4581-b6ac-8cab924def96",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"./data/news_org/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2303abdb-f209-4427-9a92-145a4b4105bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56d99f46-4e58-4f2d-9c6e-8060e8ace9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c39f1f85-96e1-466e-aadb-8626292a40b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (Segmenter, Doc)\n",
    "segmenter = Segmenter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5df830-3602-43c7-a859-81b5fba0a256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████████████                                                                                          | 101947/538362 [2:52:22<17:45:49,  6.82it/s]"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for _doc in tqdm(texts, total=total_texts):\n",
    "    text = _doc[\"raw_text\"]\n",
    "    text = preprocess(text)\n",
    "    natashadoc = Doc(text)\n",
    "    natashadoc.segment(segmenter)\n",
    "    for idx, sentence in enumerate(natashadoc.sents):\n",
    "        doc = nlp(sentence.text)\n",
    "        # Count ORG entities\n",
    "        org_count = 0\n",
    "        for span in doc.ents:\n",
    "            if span.label_ == \"ORG\":\n",
    "                org_count += 1\n",
    "        if org_count != 1:\n",
    "            continue\n",
    "        # We for sure have 1 ORG, need to take it\n",
    "        ent = None    \n",
    "        for span in doc.ents:\n",
    "            if span.label_ == \"ORG\":\n",
    "                ent = span\n",
    "                break\n",
    "                \n",
    "        data.append({\n",
    "            \"text\": sentence.text,\n",
    "            \"ent\": ent.text,\n",
    "            \"span\": [ent.start_char, ent.end_char]\n",
    "        })\n",
    "    \n",
    "    if len(data) > 2000:\n",
    "        new_path = output_dir / Path(datetime.now().isoformat() + \".json\")\n",
    "        with new_path.open(\"w\") as fout:\n",
    "            json.dump(data, fout, ensure_ascii=False)\n",
    "        data = []\n",
    "    \n",
    "        \n",
    "        \n",
    "print(\"Suffice: \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32c96e-d941-4d41-8432-d1324623f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d42bcae-0dbb-4f87-8360-ce8d6363d877",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a3fe6-0fb8-4463-9b7e-db4721e8fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a96afc9-0036-421a-abfe-20ee21efb00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mention decoder",
   "language": "python",
   "name": "mention-decoder"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
